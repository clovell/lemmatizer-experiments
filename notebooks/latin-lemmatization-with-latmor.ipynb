{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latin Lemmatization with LatMor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[LatMor](http://www.cis.uni-muenchen.de/~schmid/tools/LatMor/) is a morphological tagger for Latin based on finite-state transducer based on the [SFST toolkit](http://www.cis.uni-muenchen.de/~schmid/tools/SFST/) written by Uwe Springmann, Helmut Schmid, and Dietmar Najock in 2014. It is described in this [paper](https://www.degruyter.com/view/j/opli.2016.2.issue-1/opli-2016-0019/opli-2016-0019.xml). Like Treetagger, lemmatization is a by-product of the morphological analysis. But it is comprehensive and *very* fast, and so is useful for getting lemma information.\n",
    "\n",
    "There is no Python wrapper for LatMor. This notebook moves in that direction, using ```subprocess``` to generate command line results and then parsing them. In a future post, I will build a wrapper for LatMor that can be used with the CLTK Backoff Lemmatizer.\n",
    "\n",
    "As in the [Collatinus post](https://github.com/diyclassics/lemmatizer-experiments/blob/master/notebooks/latin-lemmatization-with-collatinus.ipynb), I use a form-frequency measure (i.e., counting the lemma that matches to the most possible forms) in order to extract a single lemma. This is still a problematic measure to be solved in a future post. LatMor results present additional challenges. Like Collatinus, punctuation is ignored. More noticeably problematic, at least from the perspective of comparing lemmatizer results, is that Latin verbs are lemmatized to their infinitive (i.e. their second principal part). Accordingly, the lemmatizer results need to be lemmatized themselves to the first principal part if the results are to be compared to, say, the TreeTagger or Collatinus results. Another task for another day.\n",
    "\n",
    "The last section of this post offers assistance with installation and configuration of TreeTagger for OSX. \\[PJB 5.11.18\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install LatMor & SFST\n",
    "\n",
    "# # See last cell for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import re\n",
    "import subprocess\n",
    "import shlex\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from cltk.tokenize.word import WordTokenizer\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances of CLTK tools\n",
    "\n",
    "tokenizer = WordTokenizer('latin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with *LatMor* and jupyter bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reading transducer from file \"/usr/local/bin/latmor/latmor.a\"...', 'finished.', '> laudat', 'laudare<V><pres><ind><active><sg><3>']\n"
     ]
    }
   ],
   "source": [
    "# Use cell magic to process bash commands\n",
    "\n",
    "test = 'laudat'\n",
    "cmd = f'echo {test} | fst-infl /usr/local/bin/latmor/latmor.a'\n",
    "result = !$cmd\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laudare<V><pres><ind><active><sg><3>\n"
     ]
    }
   ],
   "source": [
    "# Isolate the result string\n",
    "\n",
    "print(result[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laudare\n"
     ]
    }
   ],
   "source": [
    "# Use regular expressions to parse result string for lemma information\n",
    "\n",
    "m = re.search('(.+?)<', result[-1])\n",
    "print(m.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reading transducer from file \"/usr/local/bin/latmor/latmor.a\"...',\n",
      " 'finished.',\n",
      " '> amor',\n",
      " 'amare<V><pres><ind><passive><sg><1>',\n",
      " 'amor<N><masc><sg><nom>',\n",
      " 'amor<N><masc><sg><voc>']\n"
     ]
    }
   ],
   "source": [
    "# Same as above, but for a token that has more than one possible lemma\n",
    "\n",
    "test = 'amor'\n",
    "cmd = f'echo {test} | fst-infl /usr/local/bin/latmor/latmor.a'\n",
    "result = !$cmd\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amare', 'amor', 'amor']\n"
     ]
    }
   ],
   "source": [
    "# Isolate the result strings\n",
    "\n",
    "results = [r.split('<')[0] for r in result if r.endswith('>')]\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with *LatMor* and ```subprocess```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up subprocess commands\n",
    "\n",
    "token = 'amor'\n",
    "cmd1 = f'echo {token}'\n",
    "cmd2 = '/usr/local/bin/fst-infl /usr/local/bin/latmor/latmor.a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> amor\n",
      "amare<V><pres><ind><passive><sg><1>\n",
      "amor<N><masc><sg><nom>\n",
      "amor<N><masc><sg><voc>\n",
      "\n",
      "CPU times: user 2.79 ms, sys: 8.38 ms, total: 11.2 ms\n",
      "Wall time: 90 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Build subprocess pipe\n",
    "# NBL: I'll write up shlex and subprocess.PIPE at some point\n",
    "\n",
    "p1 = subprocess.Popen(shlex.split(cmd1), stdout=subprocess.PIPE)\n",
    "p2 = subprocess.Popen(shlex.split(cmd2), stdin=p1.stdout, stdout=subprocess.PIPE)\n",
    "result = p2.communicate()[0].decode()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amare', 'amor', 'amor']\n"
     ]
    }
   ],
   "source": [
    "# Parse results\n",
    "\n",
    "_result = result.split('\\n')\n",
    "results = [r.split('<')[0] for r in _result if r.endswith('>')]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a lemmatize function; use form frequency to return a single lemma\n",
    "\n",
    "def _choose_weighted_lemmas(lemmas):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    c = Counter(lemmas)\n",
    "    weights = [(i, c[i] / len(lemmas) * 100.0) for i in c]\n",
    "    if weights:\n",
    "        return max(weights,key=lambda item:item[1])[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lm_lemmatize(token):\n",
    "    cmd1 = f'echo {token}'\n",
    "    cmd2 = '/usr/local/bin/fst-infl /usr/local/bin/latmor/latmor.a'\n",
    "    p1 = subprocess.Popen(shlex.split(cmd1), stdout=subprocess.PIPE)\n",
    "    p2 = subprocess.Popen(shlex.split(cmd2), stdin=p1.stdout, stdout=subprocess.PIPE)\n",
    "    result = p2.communicate()[0].decode()\n",
    "    _result = result.split('\\n')\n",
    "    results = [r.split('<')[0] for r in _result if r.endswith('>')]\n",
    "    return _choose_weighted_lemmas(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amor\n",
      "CPU times: user 5.1 ms, sys: 9.29 ms, total: 14.4 ms\n",
      "Wall time: 123 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(lm_lemmatize('amor'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up batch fst-infl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*LatMor* is fast. But it would still be costly to make multiple calls to *LatMor* via ```subprocess```. Luckily *LatMor* can work with batches of tokens. These tokens need to be in a list separated by new line ('\\n') characters. We can accomplish this by joining a list of tokens with '\\n' and passing this to the ```echo``` command in ```subprocess```. A few things worth noting:\n",
    "- tokens are lowercased; LatMor appears to be case-sensitive, though I have not fully tested this\n",
    "- puncuation is ignored, so we check for punctuation marks and restore them to the lemma results\n",
    "- LatMor returns a list of possible lemmas; this function returns the one with the highest frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_lemmatize_batch(tokens):\n",
    "    from string import punctuation\n",
    "    text = '\\n'.join([token.lower() for token in tokens])\n",
    "    cmd1 = ['echo', text]\n",
    "    cmd2 = '/usr/local/bin/fst-infl /usr/local/bin/latmor/latmor.a'\n",
    "    p1 = subprocess.Popen(cmd1, stdout=subprocess.PIPE)\n",
    "    p2 = subprocess.Popen(shlex.split(cmd2), stdin=p1.stdout, stdout=subprocess.PIPE)\n",
    "    result = p2.communicate()[0].decode()\n",
    "    results = re.split(r'\\B> ', result)[1:]\n",
    "    lemmas = []\n",
    "    for result in results:\n",
    "        if result:\n",
    "            form = result.split('\\n')[0]\n",
    "            _lemmas = [r.split('<')[0] for r in result.split('\\n') if r.endswith('>')]\n",
    "            if _lemmas:\n",
    "                lemmas.append(_lemmas)\n",
    "            elif form in punctuation:\n",
    "                lemmas.append(form)\n",
    "            else:\n",
    "                lemmas.append(None)\n",
    "    return [_choose_weighted_lemmas(lemma) for lemma in lemmas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up sample text\n",
    "\n",
    "# Sall. Bell. Cat. 1\n",
    "text = \"\"\"Omnis homines, qui sese student praestare ceteris animalibus, summa ope niti decet, ne vitam silentio transeant veluti pecora, quae natura prona atque ventri oboedientia finxit. Sed nostra omnis vis in animo et corpore sita est: animi imperio, corporis servitio magis utimur; alterum nobis cum dis, alterum cum beluis commune est. Quo mihi rectius videtur ingeni quam virium opibus gloriam quaerere et, quoniam vita ipsa, qua fruimur, brevis est, memoriam nostri quam maxume longam efficere. Nam divitiarum et formae gloria fluxa atque fragilis est, virtus clara aeternaque habetur. Sed diu magnum inter mortalis certamen fuit, vine corporis an virtute animi res militaris magis procederet. Nam et, prius quam incipias, consulto et, ubi consulueris, mature facto opus est. Ita utrumque per se indigens alterum alterius auxilio eget.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 ms, sys: 13.2 ms, total: 35.5 ms\n",
      "Wall time: 271 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Tokenize and lemmatize sample text\n",
    "\n",
    "tokens = tokenizer.tokenize(text)\n",
    "lemmas = lm_lemmatize_batch(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Omnis', 'omnis'),\n",
      " ('homines', 'homo'),\n",
      " (',', ','),\n",
      " ('qui', 'qui'),\n",
      " ('sese', 'sese'),\n",
      " ('student', 'studere'),\n",
      " ('praestare', 'praestare'),\n",
      " ('ceteris', 'ceterus'),\n",
      " ('animalibus', 'animalis'),\n",
      " (',', ',')]\n"
     ]
    }
   ],
   "source": [
    "pprint(list(zip(tokens, lemmas))[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LatMor performance on larger text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagging performance on the entirety of Sallust's *Bellum Catilinum*\n",
    "\n",
    "from cltk.corpus.latin import latinlibrary\n",
    "bc = latinlibrary.raw('sall.1.txt')\n",
    "bc = bc[bc.find('[1]'):bc.find('Sallust The Latin Library The Classics Page')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script for preprocessing texts\n",
    "\n",
    "import html\n",
    "import re\n",
    "import string\n",
    "from cltk.stem.latin.j_v import JVReplacer\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    replacer = JVReplacer()\n",
    "    \n",
    "    text = html.unescape(text) # Handle html entities\n",
    "    text = re.sub(r'&nbsp;?', ' ',text) #&nbsp; stripped incorrectly in corpus?\n",
    "    text = re.sub(r'\\x00',' ',text) #Another space problem?\n",
    "        \n",
    "    text = text.lower()\n",
    "    text = replacer.replace(text) #Normalize u/v & i/j    \n",
    "    \n",
    "    punctuation =\"\\\"#$%&\\'()*+,-/:;<=>@[\\]^_`{|}~.?!«»—\"\n",
    "    translator = str.maketrans({key: \" \" for key in punctuation})\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    translator = str.maketrans({key: \" \" for key in '0123456789'})\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    text = re.sub('[ ]+',' ', text) # Remove double spaces\n",
    "    text = re.sub('\\s+\\n+\\s+','\\n', text) # Remove double lines and trim spaces around new lines\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10802 tokens in Sallust's *Bellum catilinae*\n"
     ]
    }
   ],
   "source": [
    "# Preprocess text\n",
    "\n",
    "bc = preprocess(bc)\n",
    "bc_tokens = tokenizer.tokenize(bc)\n",
    "print(f'There are {len(bc_tokens)} tokens in Sallust\\'s *Bellum catilinae*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.44 ms, sys: 7.38 ms, total: 10.8 ms\n",
      "Wall time: 109 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = lm_lemmatize_batch(tokens[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help with installing LatMor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The installation instructions for LatMor are included inside the zipped file package in README. What I offer here is primarily documentation of how I prefer to install Treetagger with specific attention to working with Latin.\n",
    "\n",
    "1. Download and unzip LatMor\n",
    "    - [LatMor.tar.gz](http://www.cis.uni-muenchen.de/~schmid/tools/LatMor/LatMor.tar.gz)\n",
    "3. Move the unzipped folder to ```/usr/local/bin```; a command like ```mv ./LatMor /usr/local/bin``` should work.\n",
    "4. Download and unzip [SFST](http://www.cis.uni-muenchen.de/~schmid/tools/SFST/)\n",
    "    - NB: I used v. 1.4.7d for this Notebook\n",
    "5. In the uinzipped folder, change directory to ```src```\n",
    "6. Run the following commands:\n",
    "    - ```make```\n",
    "    - ```make install```\n",
    "    - ```make maninstall```\n",
    "7. You should be all set now—try it out with the following:\n",
    "    - ```echo laudat | fst-infl /usr/local/bin/latmor/latmor.a```\n",
    "    - Output\n",
    "        - ```reading transducer from file \"/usr/local/bin/latmor/latmor.a\"...\n",
    "finished.```\n",
    "        - ```> laudat```\n",
    "        - ```laudare<V><pres><ind><active><sg><3>```\n",
    "    \n",
    "LatMor should now work as expected in the Notebooks above. If you notice any problems with the installation instructions, please open an issue in this repo.—PJB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
