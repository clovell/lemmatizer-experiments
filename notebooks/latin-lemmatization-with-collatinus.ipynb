{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latin Lemmatization with Collatinus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[*Collatinus*](http://outils.biblissima.fr/en/collatinus/) is a lemmatizer and a morphological analyser for Latin texts developed by Yves Ouvrard and Philippe Verkerk. The lemmatizer derives its results from 1. a lexicon of 11,000 Latin lemmas and 2. an inflection engine that generates possible forms. It is available as a standalone app for OSX and also has a [web version](http://outils.biblissima.fr/en/collatinus-web/). Collatinus is available under the [GNU GPL v3 license](http://www.gnu.org/licenses/gpl.html).\n",
    "\n",
    "A Python wrapper for *Collatinus*—[*PyCollatinus*](https://github.com/PonteIneptique/collatinus-python)—is now available thanks to Thibault Clérice. It generates a lot of useful information. It is also fast.\n",
    "\n",
    "In this post, I demonstrate its basic use and suggest some provisional strategies for correctly matching a token with its lemma. The key here in *correctly* matching tokens and lemmas is that *PyCollatinus* returns as many results as possible for a given form, so we need to have some way of choosing one among several option. Here is a sample result for *homines*:\n",
    "\n",
    "```\n",
    "[{'form': 'homines',\n",
    "  'lemma': 'homo',\n",
    "  'morph': 'nominatif pluriel',\n",
    "  'radical': 'homin',\n",
    "  'desinence': 'es'},\n",
    " {'form': 'homines',\n",
    "  'lemma': 'homo',\n",
    "  'morph': 'vocatif pluriel',\n",
    "  'radical': 'homin',\n",
    "  'desinence': 'es'},\n",
    " {'form': 'homines',\n",
    "  'lemma': 'homo',\n",
    "  'morph': 'accusatif pluriel',\n",
    "  'radical': 'homin',\n",
    "  'desinence': 'es'}]\n",
    "```\n",
    "\n",
    "There is no difficulty here as all three possible forms resolve to the lemma *homo*. Let's look at another, *prona*:\n",
    "\n",
    "```\n",
    "[{'form': 'prona',\n",
    "  'lemma': 'pronus',\n",
    "  'morph': 'nominatif féminin singulier',\n",
    "  'radical': 'pron',\n",
    "  'desinence': 'a'},\n",
    " {'form': 'prona',\n",
    "  'lemma': 'pronus',\n",
    "  'morph': 'vocatif féminin singulier',\n",
    "  'radical': 'pron',\n",
    "  'desinence': 'a'},\n",
    " {'form': 'prona',\n",
    "  'lemma': 'pronus',\n",
    "  'morph': 'ablatif féminin singulier',\n",
    "  'radical': 'pron',\n",
    "  'desinence': 'a'},\n",
    " {'form': 'prona',\n",
    "  'lemma': 'pronus',\n",
    "  'morph': 'nominatif neutre pluriel',\n",
    "  'radical': 'pron',\n",
    "  'desinence': 'a'},\n",
    " {'form': 'prona',\n",
    "  'lemma': 'pronus',\n",
    "  'morph': 'vocatif neutre pluriel',\n",
    "  'radical': 'pron',\n",
    "  'desinence': 'a'},\n",
    " {'form': 'prona',\n",
    "  'lemma': 'pronus',\n",
    "  'morph': 'accusatif neutre pluriel',\n",
    "  'radical': 'pron',\n",
    "  'desinence': 'a'},\n",
    " {'form': 'prona',\n",
    "  'lemma': 'prono',\n",
    "  'morph': '2ème singulier impératif présent actif',\n",
    "  'radical': 'pron',\n",
    "  'desinence': 'a'}]\n",
    "```\n",
    "\n",
    "Here we need to disambiguate between the very common *pronus* and the very uncommon *prono*. But without introducing corpus information, that is, by looking at only this result, we do not have any way of knowing what is common and uncommon. Accordingly, for this experiment, I have decided to pick the lemma that appears most often. This works (in an overdetermined way) for *homines*. It works for a word like *student* which only resolves to one lemma, *studeo*. It happens to work for *pronus*. But if we inspect the results, there are plenty of suspect cases as well: *magis* from *magus*, *natura* from *nascor*, and the infamous *est* from *edo*. In future posts, I will go through sounder solutions to disambiguation (weighting results *will* be involved, though not quite like this).\n",
    "\n",
    "Lastly, a note about punctuation. Unlike [*TreeTagger*](https://github.com/diyclassics/lemmatizer-experiments/blob/master/notebooks/latin-lemmatization-with-treetagger.ipynb), *Collatinus* does not include punctuation in the tokens to be lemmatized. Since one of the goals of these posts is to compare lemmatizers, we need to address this difference. Below I show one strategy for reintroducing the dropped punctuation so that we have comparable lemmatizer results between platforms. [PJB 5.7.18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from pycollatinus import Lemmatiseur\n",
    "\n",
    "from cltk.tokenize.word import WordTokenizer\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display \n",
    "# ^^^ Ignore cell-specific warnings ^^^\n",
    "\n",
    "# Set up lemmatizer\n",
    "\n",
    "analyzer = Lemmatiseur()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up test text\n",
    "\n",
    "# Sall. Bell. Cat. 1\n",
    "text = \"\"\"Omnis homines, qui sese student praestare ceteris animalibus, summa ope niti decet, ne vitam silentio transeant veluti pecora, quae natura prona atque ventri oboedientia finxit. Sed nostra omnis vis in animo et corpore sita est: animi imperio, corporis servitio magis utimur; alterum nobis cum dis, alterum cum beluis commune est. Quo mihi rectius videtur ingeni quam virium opibus gloriam quaerere et, quoniam vita ipsa, qua fruimur, brevis est, memoriam nostri quam maxume longam efficere. Nam divitiarum et formae gloria fluxa atque fragilis est, virtus clara aeternaque habetur. Sed diu magnum inter mortalis certamen fuit, vine corporis an virtute animi res militaris magis procederet. Nam et, prius quam incipias, consulto et, ubi consulueris, mature facto opus est. Ita utrumque per se indigens alterum alterius auxilio eget.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances of CLTK tools\n",
    "\n",
    "tokenizer = WordTokenizer('latin')\n",
    "tokens = tokenizer.tokenize(text)\n",
    "text_string = \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 151 in the sample text.\n"
     ]
    }
   ],
   "source": [
    "# Get length of token list\n",
    "\n",
    "print(f'There are {len(tokens)} in the sample text.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 83.5 ms, sys: 3.97 ms, total: 87.5 ms\n",
      "Wall time: 88.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Get Collatinus results\n",
    "\n",
    "results = analyzer.lemmatise_multiple(text_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'prona',\n",
       "  'lemma': 'pronus',\n",
       "  'morph': 'nominatif féminin singulier',\n",
       "  'radical': 'pron',\n",
       "  'desinence': 'a'},\n",
       " {'form': 'prona',\n",
       "  'lemma': 'pronus',\n",
       "  'morph': 'vocatif féminin singulier',\n",
       "  'radical': 'pron',\n",
       "  'desinence': 'a'},\n",
       " {'form': 'prona',\n",
       "  'lemma': 'pronus',\n",
       "  'morph': 'ablatif féminin singulier',\n",
       "  'radical': 'pron',\n",
       "  'desinence': 'a'},\n",
       " {'form': 'prona',\n",
       "  'lemma': 'pronus',\n",
       "  'morph': 'nominatif neutre pluriel',\n",
       "  'radical': 'pron',\n",
       "  'desinence': 'a'},\n",
       " {'form': 'prona',\n",
       "  'lemma': 'pronus',\n",
       "  'morph': 'vocatif neutre pluriel',\n",
       "  'radical': 'pron',\n",
       "  'desinence': 'a'},\n",
       " {'form': 'prona',\n",
       "  'lemma': 'pronus',\n",
       "  'morph': 'accusatif neutre pluriel',\n",
       "  'radical': 'pron',\n",
       "  'desinence': 'a'},\n",
       " {'form': 'prona',\n",
       "  'lemma': 'prono',\n",
       "  'morph': '2ème singulier impératif présent actif',\n",
       "  'radical': 'pron',\n",
       "  'desinence': 'a'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print sample of result\n",
    "\n",
    "results[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit results to only lemma info\n",
    "\n",
    "lemmas = []\n",
    "\n",
    "for result in results:\n",
    "    _lemmas = []\n",
    "    for _result in result:\n",
    "        _lemmas.append(_result['lemma'])\n",
    "    lemmas.append(_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['omne',\n",
      "  'omnis',\n",
      "  'omnis',\n",
      "  'omnis',\n",
      "  'omnis',\n",
      "  'omnis',\n",
      "  'omnis',\n",
      "  'omnis',\n",
      "  'omnis',\n",
      "  'omnis'],\n",
      " ['homo', 'homo', 'homo'],\n",
      " ['qui', 'qui', 'quis', 'queo', 'queo', 'qui']]\n"
     ]
    }
   ],
   "source": [
    "# Print lemma info\n",
    "\n",
    "pprint(lemmas[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 different lemmas in the results for 'Omnis'.\n",
      "- 10.0% omne\n",
      "- 90.0% omnis\n"
     ]
    }
   ],
   "source": [
    "# A way to weight the lemma results\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "c = Counter(lemmas[0])\n",
    "weights = [(i, c[i] / len(lemmas[0]) * 100.0) for i in c]\n",
    "\n",
    "print(f'There are {len(weights)} different lemmas in the results for \\'{tokens[0]}\\'.')\n",
    "for weight in weights:\n",
    "    print(f'- {weight[1]}% {weight[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weighted lemmas\n",
    "\n",
    "weighted_lemmas = []\n",
    "\n",
    "for lemma in lemmas:\n",
    "    c = Counter(lemma)\n",
    "    weights = [(i, c[i] / len(lemma) * 100.0) for i in c]\n",
    "    weighted_lemmas.append(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('omne', 10.0), ('omnis', 90.0)],\n",
      " [('homo', 100.0)],\n",
      " [('qui', 50.0), ('quis', 16.666666666666664), ('queo', 33.33333333333333)],\n",
      " [('se', 100.0)],\n",
      " [('studeo', 100.0)],\n",
      " [('praesto', 100.0)],\n",
      " [('ceteri', 42.857142857142854),\n",
      "  ('ceterum', 14.285714285714285),\n",
      "  ('ceterus', 42.857142857142854)],\n",
      " [('animal', 25.0), ('animalis', 75.0)],\n",
      " [('summa', 23.076923076923077),\n",
      "  ('summum', 23.076923076923077),\n",
      "  ('summus', 46.15384615384615),\n",
      "  ('summo', 7.6923076923076925)],\n",
      " [('Opis', 25.0), ('Ops', 25.0), ('ops', 25.0), ('opos', 25.0)]]\n"
     ]
    }
   ],
   "source": [
    "# Print weight lemmas\n",
    "\n",
    "pprint(weighted_lemmas[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max weight for each lemma\n",
    "\n",
    "lemma_max = []\n",
    "\n",
    "for weighted_lemma in weighted_lemmas:\n",
    "    weight_max = max(weighted_lemma,key=lambda item:item[1])[0]\n",
    "    lemma_max.append(weight_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['omnis',\n",
      " 'homo',\n",
      " 'qui',\n",
      " 'se',\n",
      " 'studeo',\n",
      " 'praesto',\n",
      " 'ceteri',\n",
      " 'animalis',\n",
      " 'summus',\n",
      " 'Opis']\n"
     ]
    }
   ],
   "source": [
    "# Print max weight\n",
    "\n",
    "pprint(lemma_max[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 151 tokens in the sample text, but only 126 lemmas!\n"
     ]
    }
   ],
   "source": [
    "# Compare lenghts of original tokens and resulting lemmas\n",
    "\n",
    "print(f'There are {len(tokens)} tokens in the sample text, but only {len(lemma_max)} lemmas!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike TreeTagger, Collatinus does not include punctuation in the tokens to be lemmatized, which explains the difference in our input and output lists. From what I have been able to determine, these are the only tokens that are ignored. Accordingly, we can easily restore punctuation by comparing the two lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align tokens & lemmas due to missing punctuation\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "lemma_pairs = []\n",
    "\n",
    "pos = 0\n",
    "for token in tokens:\n",
    "    if token in punctuation:\n",
    "        lemma_pairs.append((token, token))\n",
    "    else:\n",
    "        lemma_pairs.append((token, lemma_max[pos]))\n",
    "        pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Omnis', 'omnis'),\n",
      " ('homines', 'homo'),\n",
      " (',', ','),\n",
      " ('qui', 'qui'),\n",
      " ('sese', 'se'),\n",
      " ('student', 'studeo'),\n",
      " ('praestare', 'praesto'),\n",
      " ('ceteris', 'ceteri'),\n",
      " ('animalibus', 'animalis'),\n",
      " (',', ','),\n",
      " ('summa', 'summus'),\n",
      " ('ope', 'Opis'),\n",
      " ('niti', 'nitor'),\n",
      " ('decet', 'decet'),\n",
      " (',', ','),\n",
      " ('ne', 'ne'),\n",
      " ('vitam', 'uita'),\n",
      " ('silentio', 'silentium'),\n",
      " ('transeant', 'transeo'),\n",
      " ('veluti', 'ueluti'),\n",
      " ('pecora', 'pecus'),\n",
      " (',', ','),\n",
      " ('quae', 'qui'),\n",
      " ('natura', 'nascor'),\n",
      " ('prona', 'pronus'),\n",
      " ('atque', 'atque'),\n",
      " ('ventri', 'venter'),\n",
      " ('oboedientia', 'oboedio'),\n",
      " ('finxit', 'fingo'),\n",
      " ('.', '.'),\n",
      " ('Sed', 'sed'),\n",
      " ('nostra', 'noster'),\n",
      " ('omnis', 'omnis'),\n",
      " ('vis', 'uia'),\n",
      " ('in', 'in'),\n",
      " ('animo', 'animus'),\n",
      " ('et', 'et'),\n",
      " ('corpore', 'corpus'),\n",
      " ('sita', 'sino'),\n",
      " ('est', 'edo'),\n",
      " (':', ':'),\n",
      " ('animi', 'animus'),\n",
      " ('imperio', 'imperium'),\n",
      " (',', ','),\n",
      " ('corporis', 'corpus'),\n",
      " ('servitio', 'servitium'),\n",
      " ('magis', 'magus'),\n",
      " ('utimur', 'utor'),\n",
      " (';', ';'),\n",
      " ('alterum', 'alter')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lemma_pairs[:50])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
