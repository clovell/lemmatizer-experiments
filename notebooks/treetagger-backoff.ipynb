{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from nltk.tag.sequential import SequentialBackoffTagger\n",
    "\n",
    "from cltk.tokenize.word import WordTokenizer\n",
    "\n",
    "from treetagger import TreeTagger\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordTokenizer('latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeTaggerLemmatizer(SequentialBackoffTagger):\n",
    "    \"\"\"\"\"\"\n",
    "    def __init__(self, backoff=None):\n",
    "        \"\"\"Setup for TreeTaggerLemmatizer().\"\"\"\n",
    "        SequentialBackoffTagger.__init__(self, backoff)\n",
    "        \n",
    "        \n",
    "    def choose_tag(self, tokens, index, history):\n",
    "        \"\"\"Returns the lemma tagged in lemmatize by TreeTagger.\n",
    "        :param tokens: List of tokens to be lemmatized\n",
    "        :param index: Int with current token\n",
    "        :param history: List with tokens that have already been lemmatized\n",
    "        :return: String, spec. the token found at the current index.\n",
    "        \"\"\"\n",
    "        return tokens[index]    \n",
    "    \n",
    "    \n",
    "    def lemmatize(self, tokens):\n",
    "        \"\"\"\n",
    "        Backoff Lemmatizer wrapper for TreeTagger\n",
    "        # Note: only takes the first match (for now!) in returned lemma, \n",
    "        # i.e. 'vir|virum|virus|vis' is truncated to 'vir'. Not ideal.\n",
    "        :param tokens: List of tokens to be lemmatized\n",
    "        :return: Tuple of the form (TOKEN, LEMMA)\n",
    "        \"\"\"\n",
    "        lemmas = []\n",
    "        text = \" \".join(tokens)\n",
    "        tagger = TreeTagger(language='latin') # Error trap to see if module is installed!\n",
    "        lemmas = []\n",
    "        for _, _, lemma in tagger.tag(text):\n",
    "            if lemma == '<unknown>':\n",
    "                lemmas.append(None)\n",
    "            else:\n",
    "                lemmas.append(lemma.split('|')[0])\n",
    "        return list(zip(tokens, lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TreeTaggerLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Omnis homines, qui sese student praestare ceteris animalibus, summa ope niti decet, ne vitam silentio transeant veluti pecora, quae natura prona atque ventri oboedientia finxit. Sed nostra omnis vis in animo et corpore sita est: animi imperio, corporis servitio magis utimur; alterum nobis cum dis, alterum cum beluis commune est. Quo mihi rectius videtur ingeni quam virium opibus gloriam quaerere et, quoniam vita ipsa, qua fruimur, brevis est, memoriam nostri quam maxume longam efficere. Nam divitiarum et formae gloria fluxa atque fragilis est, virtus clara aeternaque habetur. Sed diu magnum inter mortalis certamen fuit, vine corporis an virtute animi res militaris magis procederet. Nam et, prius quam incipias, consulto et, ubi consulueris, mature facto opus est. Ita utrumque per se indigens alterum alterius auxilio eget.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 ms, sys: 6.23 ms, total: 22.9 ms\n",
      "Wall time: 2.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lemma_pairs = t.lemmatize(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Omnis', 'omnis'),\n",
      " ('homines', 'homo'),\n",
      " (',', ','),\n",
      " ('qui', 'qui'),\n",
      " ('sese', 'sui'),\n",
      " ('student', 'studeo'),\n",
      " ('praestare', 'praesto'),\n",
      " ('ceteris', 'ceterus'),\n",
      " ('animalibus', 'animal'),\n",
      " (',', ',')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lemma_pairs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" Est brilgum: tovi slimici\n",
    "In vabo tererotitant\n",
    "Brogovi sunt macresculi\n",
    "Momi rasti strugitant.\n",
    "\n",
    "\"Fuge Gabrobocchia, fili mi,\n",
    "Qui fero lacerat morsu:\n",
    "Diffide Iubiubae avi\n",
    "Es procul ab Unguimanu.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Est', 'sum'),\n",
      " ('brilgum', None),\n",
      " (':', ':'),\n",
      " ('tovi', None),\n",
      " ('slimici', None),\n",
      " ('In', None),\n",
      " ('vabo', None),\n",
      " ('tererotitant', None),\n",
      " ('Brogovi', None),\n",
      " ('sunt', 'sum')]\n"
     ]
    }
   ],
   "source": [
    "lemma_pairs = t.lemmatize(tokenizer.tokenize(text))\n",
    "pprint(lemma_pairs[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
